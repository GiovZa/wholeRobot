<launch>

<!-- Argument names for file, will probably get rid of to make code more readable -->
  <arg name="camera"                	      default="camera"/>
  <arg name="manager"             	      default="realsense2_camera_manager"/>
  <arg name="align_depth"         	      default="true"/>
  <arg name="rgb"                             default="color" />
  <arg name="depth"                           default="depth" />
  <arg name="depth_registered"                default="aligned_depth_to_color" />
  <arg name="projector"                       default="projector" />
  <arg name="bond"                            default="false" />
  <arg name="respawn"                         default="$(arg bond)" />
  <arg name="rgb_processing"                  default="true"/>
  <arg name="disparity_processing"            default="false"/>
  <arg name="disparity_registered_processing" default="false"/>
  <arg name="hw_registered_processing"        default="$(arg align_depth)" />

<!-- Launches depth camera with following parameters: 
  https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy -->
  <group ns="$(arg camera)">
    <include file="$(find realsense2_camera)/launch/includes/nodelet.launch.xml">
      <arg name="depth_width"       value="640"/>
      <arg name="depth_height"      value="480"/>
      <arg name="depth_fps"         value="30"/>
      <arg name="color_width"       value="640"/>
      <arg name="color_height"      value="480"/>
      <arg name="color_fps"         value="30"/>
      <arg name="enable_fisheye"    value="false"/>
      <arg name="enable_pointcloud" value="false"/>
      <arg name="enable_sync"       value="true"/>
      <arg name="tf_prefix"         value="$(arg camera)"/>
      <arg name="align_depth"              value="$(arg align_depth)"/>
    </include>

<!-- Launches rviz using the rgb.launch.xml file, will probably remove since it opens 3 
  camera nodes that serve no purpose, just using up precious processing speeds. ALSO: figured
  out recently that we might have to open rviz on a network configured device rather than ssh
  because the graphics for a jetson don't match with normal vm or dual boot devices --> 
    <node name="rviz" pkg="rviz" type="rviz" args="-d $(find realsense2_camera)/rviz/pointcloud.rviz" required="true" />
    <include file="$(find gen2bot)launch/rgbd.launch.xml">
      <arg name="manager"                       value="$(arg manager)" />
      <arg name="respawn"                       value="$(arg respawn)" />
      <arg name="rgb"                           value="$(arg rgb)" />
    </include>

<!-- Remaps pointcloud so that it subscribes to a topic possible for jetson to visualize -->
      <node pkg="nodelet" type="nodelet" name="points_xyzrgb_hw_registered"
            args="load depth_image_proc/point_cloud_xyzrgb $(arg manager) $(arg bond)" respawn="$(arg respawn)">
        <remap from="rgb/image_rect_color"        to="$(arg rgb)/image_rect_color" />
        <remap from="rgb/camera_info"             to="$(arg rgb)/camera_info" />
        <remap from="depth_registered/image_rect" to="$(arg depth_registered)/image_raw" />
        <remap from="depth_registered/points"     to="/camera/depth/color/points" />
      </node>

<!-- Map server used create a map that detects obstacles check out: 
  http://wiki.ros.org/octomap_server for paramter list-->
	<node pkg="octomap_server" type="octomap_server_node" name="octomap_server">
		<param name="base_frame_id" type="string" value="/base_link" />
		<param name="frame_id" type="string" value="camera_pose_frame" />
		<param name="sensor_model/max_range" value="4.0" />
		<param name="filter_ground" type="bool" value="true" />
		<param name="ground_filter/plane_distance" value="0.15" />
  <!--  <param name="ground_filter/plane_distance" value="-.05" /> -->
		<param name="pointcloud_min_z" value="-0.1" />
		<param name="pointcloud_max_z" value="0.35" />
		<remap from="cloud_in" to="/camera/depth/color/points" />
   	<remap from="projected_map" to="camera_pose_frame"/>

        	<remap from="rgb/image_rect_color"        to="$(arg rgb)/image_rect_color" />
        	<remap from="rgb/camera_info"             to="$(arg rgb)/camera_info" />
        	<remap from="depth_registered/image_rect" to="$(arg depth_registered)/image_raw" />
        	<remap from="depth_registered/points"     to="/camera/depth/color/points" />
	</node>

<!-- Launches tracking camera with following parameters: 
  https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy -->
    <group ns="$(arg camera)">
      <include file="$(find realsense2_camera)/launch/includes/nodelet.launch.xml">
        <arg name="tf_prefix"                value="$(arg camera)"/>
        <arg name="device_type"              value="t265"/>
        <arg name="json_file_path"           value=""/>
        <arg name="enable_sync"              value="false"/>

        <arg name="fisheye_fps"              value="30"/>

        <arg name="enable_gyro"              value="true"/>
        <arg name="enable_accel"             value="true"/>
        <arg name="enable_pose"              value="true"/>

        <arg name="linear_accel_cov"         value=".01"/>
        <arg name="initial_reset"            value="false"/>
        <arg name="reconnect_timeout"        value="6.0"/>
        <arg name="unite_imu_method"         value="linear_interpolation"/>
        <arg name="publish_odom_tf"          value="true"/>
        <arg name="publish_tf"               value="true"/>
        <arg name="odom_frame_id"            value="odom"/>

        
      </include>
    </group>
  </group>
 <!-- 
<!- Object recognition package to detect QR code and display both position and orientation 
  of QR code relative to camera sensor // curently commented out to focus on move_base algorithm: 
  Check out: https://github.com/bandasaikrishna/object_detection_and_3d_pose_estimation -> 

  <node name="find_object_3d" pkg="find_object_2d" type="find_object_2d" output="screen">
		<param name="settings_path" value="~/.ros/find_object_2d.ini" type="str"/>
		<param name="subscribe_depth" value="true" type="bool"/>
		<param name="session_path" value="$(find gen2bot)/sessions/qr.bin" type="str"/>
				
		<remap from="rgb/image_rect_color" to="/camera/color/image_raw"/>
		<remap from="depth_registered/image_raw" to="/camera/depth/image_rect_raw"/>
		<remap from="depth_registered/camera_info" to="/camera/depth/camera_info"/>
	</node>
	
	<node name="tf_example" pkg="find_object_2d" type="tf_example" output="screen">
	    <param name="map_frame_id" value="/camera" type="str"/>
		<param name="object_prefix" value="object" type="str"/>
	</node> 
  -->

<!-- <node pkg="amcl" type="amcl" name="amcl">
  <param name="odom_model_type" value="omni-corrected"/>
  <param name="transform_tolerance" value="0.5"/>
  <param name="odom_frame_id" value="camera_odom_frame"/> 
</node> -->

<node pkg="robot_localization" type="ekf_localization_node" name="ekf_localization" output="screen">
  <!-- Enable or disable the use of control inputs (e.g. velocity) to improve pose estimates -->
    <rosparam file="$(find gen2bot)/config/robot_localization.yaml" command="load"/>
</node>

<node pkg="tf" type="static_transform_publisher" name="camera_odom_to_base_link" args= "-0.2 0 -0.15 3.14 3.14 3.14 camera_odom_frame base_link 100"/>


<!-- Launches move_base which spews out motor commands based on nav_goal and obstacles
  Check out: http://wiki.ros.org/move_base for parameters -->
<node pkg="move_base" type="move_base" respawn="false" name="move_base" output="screen"> 
	
    <param name="controller_frequency" value="8.0" type="double"/>

<!-- Sets common_costmap parameters in config folder to both local and global costmaps -->
    <rosparam file="$(find gen2bot)/config/common_costmap.yaml" command="load" ns="global_costmap" />
    <rosparam file="$(find gen2bot)/config/common_costmap.yaml" command="load" ns="local_costmap" />
    
<!-- Sets local and global parameters in config folder to both local and global costmaps -->
    <rosparam file="$(find gen2bot)/config/local_costmap.yaml" command="load" ns="local_costmap" />
    <rosparam file="$(find gen2bot)/config/global_costmap.yaml" command="load" ns="global_costmap" /> 
</node>

<!-- Launches my listenerMotorAuto.cpp file to initialize a base controller 
  that move_base communicates with to send motor inputs. This links autonomy to motors -->
<node pkg="gen2bot" type="listenerMotorAuto" name="motorRuns" >
    <param name="initalOutput" value="0.2" type="double"/>
    <param name="isInitialState" value="true" type="bool"/>
</node>

</launch>
